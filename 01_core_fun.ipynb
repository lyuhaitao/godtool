{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d44d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638268d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from god import LhtFile\n",
    "import json\n",
    "import numpy as np\n",
    "import shutil\n",
    "import warnings\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcfb629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lht_listMethodsOfObj(obj):\n",
    "    '''\n",
    "    return a dictionary to save attributes and functions of an object.\n",
    "    '''\n",
    "    warnings.filterwarnings(\"error\")\n",
    "    func_list = []\n",
    "    attr_list = []\n",
    "    # attribute is a string representing the attribute name\n",
    "    for attribute in dir(obj):\n",
    "        # Get attribute value\n",
    "        try:\n",
    "            attribute_value = getattr(obj, attribute)\n",
    "        except:\n",
    "            continue\n",
    "        # check that it is callable\n",
    "        if callable(attribute_value):\n",
    "            # filter all __prefix methods\n",
    "            if attribute.startswith('__') == False:\n",
    "                func_list.append(attribute)\n",
    "        else:\n",
    "            attr_list.append(attribute)\n",
    "    return {'attributes':attr_list, 'functions': func_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40581a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FindFilesByExtension(root_directory, extension):\n",
    "    ret = []\n",
    "    for (root, dirs, files) in os.walk(root_directory, topdown=True):\n",
    "        for f in files:\n",
    "            if f.endswith(extension):\n",
    "                fileName = f\n",
    "                filePath = os.path.join(root,f)\n",
    "                lhtFile = LhtFile(fileName,filePath)\n",
    "                ret.append(lhtFile)\n",
    "    return ret\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9e9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "root_directory = os.getcwd()\n",
    "extension = \".ipynb\"\n",
    "ret = FindFilesByExtension(root_directory, extension)\n",
    "for i in ret:\n",
    "    print(f\"{i.file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f289cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Lht_CreateTestDataset(matrix, xSize, ySize, step):\n",
    "    '''\n",
    "    generate slide windows\n",
    "    Parameters:\n",
    "        matrix: an image array, height X width X channel\n",
    "        xSize: width of a slide window\n",
    "        ySize: height of a slide window\n",
    "        step : length of slide step. \n",
    "    Returns:\n",
    "        rtn: a list of dictionary objects\n",
    "        {'data':d, 'bbox':bbox, 'category_id': -1}\n",
    "    '''\n",
    "    rtn = []\n",
    "    rowNum = len(matrix)\n",
    "    colNum = len(matrix[0])\n",
    "    for i in range(0, colNum, step):\n",
    "        for j in range(0, rowNum, step):\n",
    "            bbox = [i,j,xSize,ySize]\n",
    "            col,row,colSize, rowSize = bbox\n",
    "            d = matrix[row:row+rowSize, col:col+colSize,:]\n",
    "            a = {'data':d, 'bbox':bbox, 'category_id': -1}\n",
    "            rtn.append(a)\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea98ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lht_compose_transforms(size):\n",
    "    '''\n",
    "    create torch composed transform object. PILImage object -> resized object -> tensor object\n",
    "    Parameter:\n",
    "        size: sequence or int. something like [h,w]\n",
    "    Return:\n",
    "        rtn: torchvision.transforms.transforms.Compose object\n",
    "    '''\n",
    "    ret = transforms.Compose([transforms.ToPILImage(), transforms.Resize(size),  transforms.ToTensor()])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ba727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.transforms.transforms.Compose"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "ret = lht_compose_transforms([224,224])\n",
    "type(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lht_load_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            obj = json.load(f)\n",
    "        return obj\n",
    "    except FileNotFoundError as err:\n",
    "        print(err)\n",
    "        return -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b76b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '321.json'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "ret = lht_load_json(\"321.json\")\n",
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8894e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def randomSelectSamples(jsonList, num):\n",
    "    '''\n",
    "    randomly select 'num' images from each folder.\n",
    "    Parameters:\n",
    "        jsonList: a list of json files\n",
    "        num: the number of you want\n",
    "    Return:\n",
    "        ret: a dictionary. \n",
    "            - ['images', 'type', 'annotations', 'categories']\n",
    "    '''\n",
    "    ret = {}\n",
    "    for js_id, js in enumerate(jsonList):\n",
    "        try:\n",
    "            obj_json = lht_load_json(js.file_path)\n",
    "            if obj_json == -1:\n",
    "                raise FileNotFoundError\n",
    "            n = len(obj_json['images'])\n",
    "\n",
    "            if n == 0:\n",
    "                raise ValueError(\"No value!\")\n",
    "            #\n",
    "            dirName = os.path.dirname(js.file_path)\n",
    "            objs = np.random.choice(obj_json['images'], num, replace=False)\n",
    "            obj_ids = [i['id'] for i in objs]\n",
    "            for obj in objs:\n",
    "                fp = dirName + \"\\\\\" + obj['file_name']\n",
    "                obj['file_path'] = fp\n",
    "            annotation = filter(lambda i: i['image_id'] in obj_ids, obj_json['annotations'])\n",
    "            annotation = list(annotation)\n",
    "            #\n",
    "            d = {'images': objs.tolist(), 'annotations': annotation, 'categories':obj_json['categories']}\n",
    "            ret[js_id] = d\n",
    "            #        \n",
    "        except FileNotFoundError as err:\n",
    "            continue\n",
    "        except ValueError as err:\n",
    "            continue\n",
    "    return ret\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lht_generate_cocojson(oldjson):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    category = [{'id':0,'category_name': \"None\"}, {'id':1,'category_name': \"animal\"}]\n",
    "    #\n",
    "    im_idx = 0\n",
    "    bb_idx = 0\n",
    "    for i in oldjson.values():\n",
    "        for im in i['images']:\n",
    "            im_id = im['id']\n",
    "            im_ann = filter(lambda m: m['image_id']==im_id, i['annotations'])\n",
    "            im_ann = list(im_ann)\n",
    "            #\n",
    "            im_newID = im_idx\n",
    "            im['id'] = im_newID\n",
    "            images.append(im)\n",
    "            for an in im_ann:\n",
    "                an['image_id'] = im_newID\n",
    "                an['id'] = bb_idx\n",
    "                an['category_id'] = 1\n",
    "                bb_idx += 1\n",
    "                annotations.append(an)\n",
    "            #\n",
    "            im_idx += 1\n",
    "    #\n",
    "    ret = {'images':images, 'annotations':annotations, 'categories': category}\n",
    "    return ret\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lhtGenerateTestData(source, destination, num):\n",
    "    '''\n",
    "    randomly copy n images from source folder to destination.\n",
    "    Parameters:\n",
    "        source: source directory path\n",
    "        destination: destination path\n",
    "        num: the number of images\n",
    "    Return:\n",
    "        ret_json: a json file that record the detail info of images\n",
    "    '''\n",
    "    target_dir = destination\n",
    "    rd = source\n",
    "    jsonList = FindFilesByExtension(rd,\".json\")\n",
    "    ret_json = randomSelectSamples(jsonList,num)\n",
    "    if os.path.exists(target_dir):\n",
    "        shutil.rmtree(target_dir)\n",
    "    os.mkdir(target_dir)\n",
    "    for v in ret_json.values():\n",
    "        for v_im in v['images']:\n",
    "            shutil.copy(v_im['file_path'], target_dir)\n",
    "            v_im.pop('file_path', None)\n",
    "    #\n",
    "    ret_coco = lht_generate_cocojson(ret_json)\n",
    "    fp = target_dir + \"\\\\\" + \"test.json\"\n",
    "    with open(fp, 'w') as fin:\n",
    "        json.dump(ret_coco, fin)\n",
    "    # \n",
    "    return ret_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee633052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def searchImageByName(image_name,js_dict):\n",
    "    '''\n",
    "    search images by its name, and return its index in a json file.\n",
    "    Parameters:\n",
    "        image_name: an image's name\n",
    "        js_dict: a dictionary loaded from a json file, where save all details\n",
    "    Return:\n",
    "        a list where save the search results.\n",
    "    '''\n",
    "    images = js_dict['images']\n",
    "    m = filter(lambda i: i['file_name'] == image_name, images)\n",
    "    m = list(m)\n",
    "    return m if len(m) >0 else -1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecb07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def Lht_SlideWindow(matrix,xSize, ySize, step):\n",
    "    rowNum = len(matrix)\n",
    "    colNum = len(matrix[0])\n",
    "    rtn = []\n",
    "    for i in range(0, colNum, step):\n",
    "        for j in range(0, rowNum, step):\n",
    "            bbox = [i,j,xSize,ySize]\n",
    "            rtn.append(bbox)\n",
    "    return rtn\n",
    "    pass\n",
    "\n",
    "def isInclude(bbox1, bbox2):\n",
    "    '''\n",
    "    judge whether bbox1 contains bbox2\n",
    "    '''\n",
    "    x1,y1,xs1, ys1 = bbox1\n",
    "    x2,y2,xs2, ys2 = bbox2\n",
    "    rtn = x1 <= x2 and y1 <= y2 and x1+xs1 >= x2+xs2 and y1+ys1 >= y2+ys2\n",
    "    return rtn\n",
    "\n",
    "#\n",
    "def CreateAnnotation(**kwargs):\n",
    "    '''\n",
    "    invoke the following functions:\n",
    "        Lht_SlideWindow, isInclude\n",
    "    '''\n",
    "    annotations = []\n",
    "    root_directory = kwargs['root_directory']\n",
    "    image = kwargs['image']\n",
    "    xSize = kwargs['xSize']\n",
    "    ySize = kwargs['ySize']\n",
    "    step  = kwargs['step']\n",
    "    bboxes = kwargs['bboxes']\n",
    "    #\n",
    "    image_id = image['id']\n",
    "    img_file_name = image['file_name']\n",
    "    img_path = os.path.join(root_directory, img_file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    #\n",
    "    def fn_contain_yes(sw):\n",
    "        rtn = []\n",
    "        for i in bboxes:\n",
    "            bbox2 = i['bbox']\n",
    "            a = isInclude(sw, bbox2)\n",
    "            rtn.append(a)\n",
    "        return np.any(rtn)\n",
    "        \n",
    "    def fn_contain_no(sw):\n",
    "        rtn = []\n",
    "        for i in bboxes:\n",
    "            bbox2 = i['bbox']\n",
    "            a = isInclude(sw, bbox2)\n",
    "            rtn.append(not a)\n",
    "        return np.all(rtn)\n",
    "        \n",
    "    #\n",
    "    sws = Lht_SlideWindow(img, xSize,ySize, step)\n",
    "    a = filter(fn_contain_yes, sws)\n",
    "    bboxes_contain_yes = list(a)\n",
    "    a = filter(fn_contain_no, sws)\n",
    "    bboxes_contain_no = list(a)\n",
    "    idx_no = np.random.choice(len(bboxes_contain_no),len(bboxes_contain_yes), replace=False)\n",
    "    # category_id: 1 -> animal; 0 -> no animal\n",
    "    for i in bboxes_contain_yes:\n",
    "        tmp = {'bbox': i, 'image_id':image_id, 'category_id':1}\n",
    "        annotations.append(tmp)\n",
    "    #\n",
    "    for j in idx_no:\n",
    "        i = bboxes_contain_no[j]\n",
    "        tmp = {'bbox': i, 'image_id':image_id, 'category_id':0}\n",
    "        annotations.append(tmp)\n",
    "    return annotations\n",
    "    pass\n",
    "#\n",
    "def GenerateTrainDateByJson(**kwargs):\n",
    "    '''\n",
    "    generate training dataset by json file\n",
    "    invoke the function: CreateAnnotation\n",
    "    parameters:\n",
    "        root_directory\n",
    "        json: Lht_File object\n",
    "        xSize: \n",
    "        ySize:\n",
    "        step: the sliding length of slide window\n",
    "        desc: simple description used in tqdm\n",
    "    '''\n",
    "    annotations = []\n",
    "    root_directory = kwargs['root_directory']\n",
    "    obj_json = kwargs['json']\n",
    "    xSize = kwargs['xSize']\n",
    "    ySize = kwargs['ySize']\n",
    "    step  = kwargs['step']\n",
    "    desc  = '' if kwargs['desc'] is None else kwargs['desc']\n",
    "    #\n",
    "    rtn_images = []\n",
    "    images = obj_json['images']\n",
    "    old_annotations = obj_json['annotations']\n",
    "    categories = [{'id':1, 'name':'animal'}, {'id':0, 'name':'others'}]\n",
    "    for image in tqdm(images, desc=desc):\n",
    "        # judge whether there exists a image\n",
    "        img_file_name = image['file_name']\n",
    "        img_path = os.path.join(root_directory, img_file_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            continue\n",
    "        # save availabe image to a list\n",
    "        rtn_images.append(image)\n",
    "        #\n",
    "        fun = lambda x: x['image_id']== image['id']\n",
    "        d = filter(fun, old_annotations)\n",
    "        d = list(d)\n",
    "        #\n",
    "        a = {'image':image, 'xSize':xSize, 'ySize':ySize, 'step':step, 'bboxes':d, 'root_directory': root_directory}\n",
    "        r = CreateAnnotation(**a)\n",
    "        annotations += r \n",
    "    #\n",
    "    rtn = {'images':rtn_images, 'annotations': annotations, 'categories':categories, 'root':root_directory}\n",
    "    return rtn\n",
    "    pass\n",
    "#\n",
    "def LhtConstructDSByImageID(image_id, ds):\n",
    "    annotations = ds['annotations']\n",
    "    images = ds['images']\n",
    "    root_directory = ds['root']\n",
    "    a = filter(lambda x: x['id'] == image_id, images)\n",
    "    a = list(a)\n",
    "    image = a[0]\n",
    "    img_path = os.path.join(root_directory, image['file_name'])\n",
    "    # read an image, and then convert it to be grayscale\n",
    "    img = Image.open(img_path)\n",
    "    #img = ImageOps.grayscale(img)\n",
    "    img = np.asarray(img)\n",
    "    #img = np.stack((img,img,img), axis=2)\n",
    "    #\n",
    "    ans = filter(lambda x: x['image_id']==image_id, annotations)\n",
    "    ans = list(ans)\n",
    "    rtn = []\n",
    "    for i in ans:\n",
    "        bbox = np.int32(i['bbox'])\n",
    "        col,row,colSize, rowSize = bbox\n",
    "        d = img[row:row+rowSize, col:col+colSize,:]\n",
    "        f = i['category_id']\n",
    "        a = {'data':d, 'bbox':bbox, 'category_id': f}\n",
    "        rtn.append(a)\n",
    "    #\n",
    "    return rtn\n",
    "    pass\n",
    "#\n",
    "def LhtGetDataByJson(ds):\n",
    "    rtn = []   \n",
    "    images = ds['images']\n",
    "    for image in tqdm(images,desc=ds['root']):\n",
    "        image_id = image['id']\n",
    "        a = LhtConstructDSByImageID(image_id, ds)\n",
    "        rtn += a\n",
    "    #\n",
    "    return rtn\n",
    "    pass\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014dc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f427b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_torch",
   "language": "python",
   "name": "env_torch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
